# 타이타닉 생존자 예측하기
## 데이터 확인하기
* 모듈을 가져옵니다.
```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline
```

* 데이터를 가져옵니다.
* 경로를 잘 확인합니다.
```python
raw_data = pd.read_excel('./titanic.xls')
raw_data.info()
```

* 통계 정보를 확인합니다.
```python
raw_data.describe()
```

* 데이터를 확인합니다.
```python
raw_data.head()
```

* 살아남는 사람 관련 데이터를 시각화합니다.
* value_counts()를 이용하면 해당 항목의 숫자를 합칩니다.
```python
f,ax=plt.subplots(1,2,figsize=(12,6))

raw_data['survived'].value_counts().plot.pie(explode=[0.1,0.1],
                                             autopct='%1.2f%%',ax=ax[0])
ax[0].set_title('Survived')
ax[0].set_ylabel('')

sns.countplot(x='survived', data=raw_data,ax=ax[1])
ax[1].set_title('Survived')
plt.show()
```

* age 항목을 히스토그램으로 그립니다.
* bins는 세로축의 칸 간격입니다.
```python
raw_data['age'].hist(bins=20,figsize=(18,8),grid=False)
```

* groupby 명령어를 사용하면 지정된 칼럼을 index로 데이터를 정렬합니다.
* mean()으로 평균 확인합니다.
```python
raw_data.groupby('pclass').mean()
```

* corr() 함수는 상관계수를 계산해주는 함수입니다.
* seaborn의 heatmap과 함께 보면 시작적 효과가 좋습니다.
* 상관관계와 인과관계는 다릅니다.
```python
plt.figure(figsize=(10, 10))
sns.heatmap(raw_data.corr(), linewidths=0.01, square=True,
            annot=True, cmap=plt.cm.viridis, linecolor="white")
plt.title('Correlation between features')
plt.show()
```

* cut 함수를 사용해서 나이 기준을 만들고 그 각각에 이름을 붙입니다.
```python
raw_data['age_cat'] = pd.cut(raw_data['age'],bins=[0, 3, 7, 15, 30, 60, 100],include_lowest=True,labels=['baby', 'children', 'teenage','young', 'adult', 'old'])
raw_data.head()
```

* 평균을 확인합니다.
```python
raw_data.groupby('age_cat').mean()
```

* 시각화합니다.
```python
# plt.subplot 의 입력값은 행의수, 열의수, index 
# 131-1행 3열에서 1번째
plt.figure(figsize=[14,4])
plt.subplot(131)
sns.barplot(x='pclass', y='survived', data=raw_data)
plt.subplot(132)
sns.barplot(x='age_cat', y='survived', data=raw_data)
plt.subplot(133)
sns.barplot(x='sex', y='survived', data=raw_data)
plt.subplots_adjust(top=1, bottom=0.1, left=0.10, right=1, hspace=0.5, wspace=0.5)
plt.show()
```

* 성별로 확인합니다.
```python
f,ax=plt.subplots(1,2,figsize=(12,6))
sns.countplot(x='sex',data=raw_data, ax=ax[0])
ax[0].set_title('Count of Passengers by Sex')

sns.countplot(x='sex',hue='survived',data=raw_data, ax=ax[1])
ax[1].set_title('Sex:Survived vs Dead')
plt.show()
```

## 머신러닝으로 예측하기
* 데이터를 숫자로 바꿉니다.
* 여자는 0, 남자는 1로 바꿉니다.
```python
tmp = []
for each in raw_data['sex']:
    if each == 'female':
        tmp.append(0)
    elif each == 'male':
        tmp.append(1)
    else:
        tmp.append(np.nan)
```

* astype 함수로 데이터를 실수(예:12.12)로 만듭니다.
```python
raw_data['survived'] = raw_data['survived'].astype('float')
raw_data['pclass'] = raw_data['pclass'].astype('float')
raw_data['sex'] = raw_data['sex'].astype('float')
raw_data['sibsp'] = raw_data['sibsp'].astype('float')
raw_data['parch'] = raw_data['parch'].astype('float')
raw_data['fare'] = raw_data['fare'].astype('float')
raw_data.head()
```

* notnull로 정보가 없는 것은 제외합니다.
```python
raw_data = raw_data[raw_data['age'].notnull()]
raw_data = raw_data[raw_data['sibsp'].notnull()]
raw_data = raw_data[raw_data['parch'].notnull()]
raw_data = raw_data[raw_data['fare'].notnull()]
raw_data.info()
```

* pclass : 객실
* sex : 성별
* age : 나이
* sibsp : 동반한 Sibling(형제자매)와 Spouse(배우자)의 수
* parch : 동반한 Parent(부모) Child(자식)의 수
* fare : 요금
```python
train_pre = raw_data[['pclass','sex','age','sibsp','parch','fare']]
train_pre.head()
```

* 학습 데이터와 테스트 데이터를 분류합니다.
```python
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(train_pre, raw_data[['survived']], test_size=0.1, random_state=13)
```

* ```X_train.head()```를 하면 앞에 raw_data에 있는 번호가 붙는 것을 볼 수 있습니다.
* 이것을 다시 리셋합니다. 그러면 index가 순서대로 바뀝니다.
```python
X_train = X_train.reset_index()
X_train = X_train.drop(['index'], axis=1)

X_test = X_test.reset_index()
X_test = X_test.drop(['index'], axis=1)

y_train = y_train.reset_index()
y_train = y_train.drop(['index'], axis=1)

y_test = y_test.reset_index()
y_test = y_test.drop(['index'], axis=1)
```

* DecisionTreeClassifier 객체를 만듭니다.
* fit으로 학습합니다.
* 훈련용 데이터에서 정확도를 확인합니다.
```python
from sklearn.tree import DecisionTreeClassifier

tree_clf = DecisionTreeClassifier(max_depth=3, random_state=13)
tree_clf.fit(X_train, y_train)

print('Score: {}'.format(tree_clf.score(X_train, y_train)))
```

* 예측을 잘 하는지 정확도를 확인합니다.
```python
from sklearn.metrics import accuracy_score

y_pred = tree_clf.predict(X_test)
print("Test Accuracy is ", accuracy_score(y_test, y_pred)*100)
```

* 실제 데이터로 생존 여부를 예측합니다.
```python
dicaprio = [3., 1., 19., 0., 0., 5.]
winslet = [1., 0., 17., 1., 1., 100.]
```
```python
tree_clf.predict_proba([winslet])
```
```python
tree_clf.predict_proba([dicaprio])
```
